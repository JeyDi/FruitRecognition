{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Functions\n",
    "-------------------\n",
    "Common general and useful functions for different notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Keras Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveKerasModel(model,model_name,path=None):\n",
    "    \"\"\"Save Keras model to disk\n",
    "    INPUT:\n",
    "    - model\n",
    "    - name of the model\n",
    "    - eventually the path where you want to save\n",
    "    \"\"\"\n",
    "    import onnx\n",
    "    import keras2onnx\n",
    "    import os\n",
    "    \n",
    "    check = True\n",
    "    \n",
    "    #Convert to ONNX\n",
    "    try:\n",
    "        onnx_model = keras2onnx.convert_keras(model, model_name)\n",
    "        print(\"Type of the model:\",type(onnx_model))\n",
    "        check = True\n",
    "        \n",
    "    except:\n",
    "        print(\"Impossibile to serialize the model, please check the code and retry\")\n",
    "        check = False\n",
    "        return check\n",
    "    \n",
    "    #Build the path and Save the model on disk\n",
    "    \n",
    "    if(path is None):\n",
    "        path = \"..\\models\"\n",
    "    else:\n",
    "        path = path\n",
    "        \n",
    "    path_onnx = os.path.join(path,model_name + \".onnx\")\n",
    "    print(\"Path of the model:\",path_onnx)\n",
    "    \n",
    "    try:\n",
    "        #Save model to disk\n",
    "        onnx.save(onnx_model, path_onnx)\n",
    "        print(\"Model\",model_name,\"saved in:\",path_onnx)\n",
    "        return check\n",
    "    \n",
    "    except:\n",
    "        print(\"Impossibile to save the model, please check the code and retry\")\n",
    "        check = False\n",
    "        return check\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Keras Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadKerasModel(path,name=None):\n",
    "    \"\"\"Load ONNX Model on Keras\n",
    "    INPUT:\n",
    "    - path where the model is\n",
    "    - eventually the name of the model\n",
    "    \"\"\"\n",
    "    import onnx\n",
    "    import keras2onnx\n",
    "    import os\n",
    "    \n",
    "    check = True\n",
    "    \n",
    "    if(name is None):\n",
    "        file_path = path\n",
    "    else:\n",
    "        name = name + \".onnx\"\n",
    "        file_path = os.path.join(path,name)\n",
    "        \n",
    "    onnx_model = onnx.load(file_path)\n",
    "    \n",
    "    print(\"Model loaded:\",file_path)\n",
    "    \n",
    "    return onnx_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the best results for a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectBestResults(model1_history,model2_history):\n",
    "    \"\"\"Select best results from 2 models\n",
    "    INPUT:\n",
    "    - first model history\n",
    "    - second model history\n",
    "    \"\"\"\n",
    "    model1_acc = max(model1_history.history['val_acc'])\n",
    "    model1_loss = min(model1_history.history['val_loss'])\n",
    "    \n",
    "    model2_acc = max(model1_history.history['val_acc'])\n",
    "    model2_loss = min(model2_history.history['val_loss'])\n",
    "     \n",
    "    print(\"\\nBest results for the model\")\n",
    "    print(\"Model1 Acc:\",model1_acc)\n",
    "    print(\"Model1 Loss:\",model1_loss)\n",
    "    print(\"Model2 Acc:\",model2_acc)\n",
    "    print(\"Model2 Loss:\",model2_loss)\n",
    "    \n",
    "    model = 0\n",
    "    \n",
    "    #check the best accuracy\n",
    "    if(model1_acc > model2_acc):\n",
    "        print(\"Model 1 best acc\")\n",
    "        model = 1\n",
    "        return model\n",
    "    \n",
    "    elif (model1_acc < model2_acc):\n",
    "        print(\"Model 2 best acc\")\n",
    "        model = 2\n",
    "        return model\n",
    "    \n",
    "    #if the two model are equal, check the lowest loss\n",
    "    else:\n",
    "        if(model1_loss <= model2_loss):\n",
    "            print(\"Model 1 best loss\")\n",
    "            model = 1\n",
    "            return model\n",
    "        \n",
    "        else:\n",
    "            print(\"Model 2 best loss\")\n",
    "            model = 2\n",
    "            return model \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seeErrors(validation_dir,validation_generator,model,display=False):\n",
    "    \"\"\"Function that allow to see training errors from model\n",
    "    INPUTS:\n",
    "    - validation_dir = directory of the validation dataset\n",
    "    - validation_generator = generator of images\n",
    "    - model = model trained\n",
    "    - display = flag, if you set to True, you can visualize the first 10 errors into your error vector\n",
    "    WARNING = remember to set the shuffle = false flag inside the validation_generator \n",
    "                    if you want to compare the prediction with the ground truth!!!\n",
    "    \"\"\"\n",
    "    from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "    \n",
    "    # Get the filenames from the generator\n",
    "    fnames = validation_generator.filenames\n",
    "\n",
    "    # Get the ground truth from generator\n",
    "    ground_truth = validation_generator.classes\n",
    "\n",
    "    # Get the label to class mapping from the generator\n",
    "    label2index = validation_generator.class_indices\n",
    "\n",
    "    # Getting the mapping from class index to class label\n",
    "    idx2label = dict((v,k) for k,v in label2index.items())\n",
    "\n",
    "    # Get the predictions from the model using the generator\n",
    "    predictions = model.predict_generator(validation_generator,\n",
    "                                          steps=validation_generator.samples/validation_generator.batch_size,\n",
    "                                          verbose=0)\n",
    "    \n",
    "    print(\"\\nPrediction completed\")\n",
    "    \n",
    "    predicted_classes = np.argmax(predictions,axis=1)\n",
    "\n",
    "    #Check the number of errors\n",
    "    errors = np.where(predicted_classes != ground_truth)[0]\n",
    "    print(\"No of errors = {}/{}\".format(len(errors),validation_generator.samples))\n",
    "    \n",
    "    #code to display images from the error vector\n",
    "    if(display is True):\n",
    "        # Show the errors for the first 10 images inside error vector\n",
    "        for i in range(len(errors[:10])):\n",
    "            pred_class = np.argmax(predictions[errors[i]])\n",
    "            pred_label = idx2label[pred_class]\n",
    "\n",
    "            title = 'Original label:{}, Prediction :{}, confidence : {:.3f}'.format(\n",
    "                fnames[errors[i]].split('/')[0],\n",
    "                pred_label,\n",
    "                predictions[errors[i]][pred_class])\n",
    "\n",
    "            original = load_img('{}/{}'.format(validation_dir,fnames[errors[i]]))\n",
    "            plt.figure(figsize=[7,7])\n",
    "            plt.axis('off')\n",
    "            plt.title(title)\n",
    "            plt.imshow(original)\n",
    "            plt.show()\n",
    "    elif(display is False):\n",
    "        print(\"Errors not printed\")\n",
    "        \n",
    "    return errors,predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveStandardModel(model,model_name,path=None):\n",
    "    import os\n",
    "    \n",
    "    check = True\n",
    "    \n",
    "    if(path is None):\n",
    "        path = \"..\\models\"\n",
    "    else:\n",
    "        path = path\n",
    "        \n",
    "    file_path = os.path.join(path,model_name + \".h5\")\n",
    "    print(\"Path of the model:\",file_path)\n",
    "    \n",
    "    try:\n",
    "        #Save model to disk\n",
    "        model.save(file_path)  # creates a HDF5 file 'my_model.h5'\n",
    "        print(\"Model\",model_name,\"saved in:\",file_path)\n",
    "        return check\n",
    "    \n",
    "    except:\n",
    "        print(\"Impossibile to save the model, please check the code and retry\")\n",
    "        check = False\n",
    "        return check\n",
    "        \n",
    "    \n",
    "    print(\"Model saved:\",file_path)\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadStandardModel(path,name=None):\n",
    "    \n",
    "    from keras.models import load_model\n",
    "    \n",
    "    if(name is None):\n",
    "        file_path = path\n",
    "    else:\n",
    "        name = name + \".h5\"\n",
    "        file_path = os.path.join(path,name)\n",
    "        \n",
    "    model = load_model(file_path)  # creates a HDF5 file 'my_model.h5'\n",
    "    \n",
    "    print(\"Model loaded:\",file_path)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeImage(directory,img_name,target_size = None):\n",
    "    \"\"\"Visualize an image\n",
    "    INPUT PARAMETERS:\n",
    "    - directory = directory path where the image is\n",
    "    - img_name = name of the image (need to specify the extension: jpg, png, ...)\n",
    "    - targer_size = size of the image do you want to visualize\n",
    "    \"\"\"\n",
    "    import os\n",
    "    \n",
    "    #image_path = test_dir + \"Apple Braeburn/37_100.jpg\"\n",
    "    \n",
    "    if(target_size is None):\n",
    "        target_size = 100\n",
    "    \n",
    "    image_path = os.path.join(directory, img_name)\n",
    "    \n",
    "    #load the image\n",
    "    test_image = keras.preprocessing.image.img_to_array(keras.preprocessing.image.load_img(image_path,target_size=(target_size, target_size)))\n",
    "    \n",
    "    #rescale the image\n",
    "    test_image = test_image/255\n",
    "\n",
    "    plt.imshow(test_image)\n",
    "    \n",
    "    return test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(classes,validation_generator,predictions):\n",
    "    #Code for generating confusion matrix over the classes\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    import seaborn as sn\n",
    "\n",
    "    print('Creating Confusion Matrix')\n",
    "    conf_matrix_dataset = confusion_matrix(validation_generator.classes, predictions)\n",
    "\n",
    "    print('Creating Classification Report')\n",
    "    classification_report = classification_report(validation_generator.classes, predictions)\n",
    "\n",
    "    print('Creating final heatmap for the confusion matrix')\n",
    "    \n",
    "    df_cm = pd.DataFrame(conf_matrix_dataset, range(classes),\n",
    "                      range(classes))\n",
    "    plt.figure(figsize = (classes,classes))\n",
    "    \n",
    "    map_confusion = sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 10})# font size\n",
    "    \n",
    "    \n",
    "    return map_confusion,conf_matrix_dataset,classification_report\n",
    "\n",
    "#Original code for the confusion matrix\n",
    "# df_cm = pd.DataFrame(Confusion_matrix, range(103),\n",
    "#                   range(103))\n",
    "# plt.figure(figsize = (103,103))\n",
    "# sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 10})# font size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
